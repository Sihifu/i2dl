{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time: 0.017284 seconds\n",
      "GPU Time (using MPS): 0.001121 seconds\n",
      "Speedup using GPU (MPS): 15.42x\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Set the matrix size\n",
    "matrix_size = 1000\n",
    "\n",
    "# Generate two random matrices\n",
    "A = torch.randn(matrix_size, matrix_size)\n",
    "B = torch.randn(matrix_size, matrix_size)\n",
    "\n",
    "# Function to perform matrix multiplication on CPU\n",
    "def cpu_matrix_multiplication(A, B):\n",
    "    # Ensure tensors are on the CPU\n",
    "    A = A.to('cpu')\n",
    "    B = B.to('cpu')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = torch.mm(A, B)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return end_time - start_time, result\n",
    "\n",
    "# Function to perform matrix multiplication on GPU\n",
    "def gpu_matrix_multiplication(A, B):\n",
    "    # Ensure tensors are on the GPU\n",
    "    A = A.to('mps')  # Use 'mps' for Metal Performance Shaders on M1/M2\n",
    "    B = B.to('mps')\n",
    "    \n",
    "    # Warm-up to ensure accurate timing\n",
    "    torch.mm(A, B)\n",
    "    \n",
    "    # Perform matrix multiplication\n",
    "    start_time = time.time()\n",
    "    result = torch.mm(A, B)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return end_time - start_time, result\n",
    "\n",
    "# Perform the matrix multiplication on CPU\n",
    "cpu_time, res_cpu = cpu_matrix_multiplication(A, B)\n",
    "print(f\"CPU Time: {cpu_time:.6f} seconds\")\n",
    "\n",
    "# Perform the matrix multiplication on GPU\n",
    "gpu_time, res_gpu = gpu_matrix_multiplication(A, B)\n",
    "print(f\"GPU Time (using MPS): {gpu_time:.6f} seconds\")\n",
    "\n",
    "# Compare the results\n",
    "speedup = cpu_time / gpu_time\n",
    "print(f\"Speedup using GPU (MPS): {speedup:.2f}x\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=np.array([[1,2,3],[4,5,6]])\n",
    "W1=np.array([[6,7],[3,3],[2,2]])\n",
    "Y1=X1@W1\n",
    "f=lambda x: x+1\n",
    "df=lambda x: np.ones(x.shape)\n",
    "y_out=f(Y1)\n",
    "L=np.sum(y_out,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 7],\n",
       "       [3, 3],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18, 19],\n",
       "       [51, 55]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 20],\n",
       "       [52, 56]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39, 108])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dyout=np.ones((2,2))\n",
    "dyout_Y1=df(Y1)\n",
    "Y1_W1=X1.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dyout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyout_Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyout_Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyout_Y1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('self', 'params', 'lr', 'betas', 'eps', 'weight_decay', 'amsgrad')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func=torch.optim.Adam.__init__\n",
    "adam_params = func.__code__.co_varnames[:func.__code__.co_argcount]\n",
    "adam_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams={\"lr\": 1, \"a\":2}\n",
    "parsed_arguments={ key: value for key,value in hparams.items() if key in adam_params}\n",
    "parsed_arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 1, 'b': 20}, {'a': 1, 'b': 25}, {'a': 3, 'b': 20}, {'a': 3, 'b': 25}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "grid_search_spaces={\"a\":[1,3], \"b\":[20,25]}\n",
    "configs = []\n",
    "\n",
    "\n",
    "    # More general implementation using itertools\n",
    "for instance in product(*grid_search_spaces.values()):\n",
    "    configs.append(dict(zip(grid_search_spaces.keys(), instance)))\n",
    "\n",
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5324],\n",
      "        [-0.6000],\n",
      "        [-0.0990],\n",
      "        [-0.3604],\n",
      "        [ 0.2153]], grad_fn=<AddmmBackward0>)\n",
      "501\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ShortcutModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ShortcutModel, self).__init__()\n",
    "        # Linear layer\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # Batch normalization layer\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        ## combinde\n",
    "        self.ffs=nn.Sequential(self.fc1,self.bn,nn.ReLU())\n",
    "\n",
    "        # Shortcut connection (identity mapping)\n",
    "        if input_size != hidden_size:\n",
    "            # If input and output dimensions are different, use a linear layer to match dimensions\n",
    "            self.shortcut = nn.Linear(input_size, hidden_size)\n",
    "        else:\n",
    "            # Identity mapping if dimensions match\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First linear transformation\n",
    "        #out = self.fc1(x)\n",
    "        \n",
    "        # Batch normalization and activation\n",
    "        #out = self.bn(out)\n",
    "        #out = F.relu(out)\n",
    "        \n",
    "        # Shortcut connection (adding the input to the transformed output)\n",
    "        shortcut = self.shortcut(x)\n",
    "        out =self.ffs(x)\n",
    "        out += shortcut\n",
    "        \n",
    "        # Pass through output layer\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Example usage\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 1\n",
    "model = ShortcutModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Example input tensor\n",
    "x = torch.randn(5, input_size)\n",
    "output = model(x)\n",
    "\n",
    "print(output)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.optim.adam.Adam"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams[\"optimizer\"]=\"Adam\"\n",
    "getattr(torch.optim, hparams[\"optimizer\"].capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.loss.CrossEntropyLoss"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(torch.nn, \"CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.ones((1,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(10).reshape((2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = np.mean(x, axis=0)\n",
    "\n",
    "x_minus_mean = x - sample_mean[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.5, -2.5, -2.5, -2.5, -2.5],\n",
       "       [ 2.5,  2.5,  2.5,  2.5,  2.5]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_minus_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
