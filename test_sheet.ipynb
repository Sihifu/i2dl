{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time: 0.011946 seconds\n",
      "GPU Time (using MPS): 0.000243 seconds\n",
      "Speedup using GPU (MPS): 49.17x\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Set the matrix size\n",
    "matrix_size = 1000\n",
    "\n",
    "# Generate two random matrices\n",
    "A = torch.randn(matrix_size, matrix_size)\n",
    "B = torch.randn(matrix_size, matrix_size)\n",
    "\n",
    "# Function to perform matrix multiplication on CPU\n",
    "def cpu_matrix_multiplication(A, B):\n",
    "    # Ensure tensors are on the CPU\n",
    "    A = A.to('cpu')\n",
    "    B = B.to('cpu')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = torch.mm(A, B)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return end_time - start_time, result\n",
    "\n",
    "# Function to perform matrix multiplication on GPU\n",
    "def gpu_matrix_multiplication(A, B):\n",
    "    # Ensure tensors are on the GPU\n",
    "    A = A.to('mps')  # Use 'mps' for Metal Performance Shaders on M1/M2\n",
    "    B = B.to('mps')\n",
    "    \n",
    "    # Warm-up to ensure accurate timing\n",
    "    torch.mm(A, B)\n",
    "    \n",
    "    # Perform matrix multiplication\n",
    "    start_time = time.time()\n",
    "    result = torch.mm(A, B)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return end_time - start_time, result\n",
    "\n",
    "# Perform the matrix multiplication on CPU\n",
    "cpu_time, res_cpu = cpu_matrix_multiplication(A, B)\n",
    "print(f\"CPU Time: {cpu_time:.6f} seconds\")\n",
    "\n",
    "# Perform the matrix multiplication on GPU\n",
    "gpu_time, res_gpu = gpu_matrix_multiplication(A, B)\n",
    "print(f\"GPU Time (using MPS): {gpu_time:.6f} seconds\")\n",
    "\n",
    "# Compare the results\n",
    "speedup = cpu_time / gpu_time\n",
    "print(f\"Speedup using GPU (MPS): {speedup:.2f}x\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=np.array([[1,2,3],[4,5,6]])\n",
    "W1=np.array([[6,7],[3,3],[2,2]])\n",
    "Y1=X1@W1\n",
    "f=lambda x: x+1\n",
    "df=lambda x: np.ones(x.shape)\n",
    "y_out=f(Y1)\n",
    "L=np.sum(y_out,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 7],\n",
       "       [3, 3],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18, 19],\n",
       "       [51, 55]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 20],\n",
       "       [52, 56]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39, 108])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dyout=np.ones((2,2))\n",
    "dyout_Y1=df(Y1)\n",
    "Y1_W1=X1.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dyout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyout_Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyout_Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyout_Y1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('self', 'params', 'lr', 'betas', 'eps', 'weight_decay', 'amsgrad')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func=torch.optim.Adam.__init__\n",
    "adam_params = func.__code__.co_varnames[:func.__code__.co_argcount]\n",
    "adam_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams={\"lr\": 1, \"a\":2}\n",
    "parsed_arguments={ key: value for key,value in hparams.items() if key in adam_params}\n",
    "parsed_arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 1, 'b': 20}, {'a': 1, 'b': 25}, {'a': 3, 'b': 20}, {'a': 3, 'b': 25}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "grid_search_spaces={\"a\":[1,3], \"b\":[20,25]}\n",
    "configs = []\n",
    "\n",
    "\n",
    "    # More general implementation using itertools\n",
    "for instance in product(*grid_search_spaces.values()):\n",
    "    configs.append(dict(zip(grid_search_spaces.keys(), instance)))\n",
    "\n",
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0587],\n",
      "        [ 0.3325],\n",
      "        [-0.5717],\n",
      "        [ 0.5167],\n",
      "        [-0.1494]], grad_fn=<AddmmBackward0>)\n",
      "501\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ShortcutModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ShortcutModel, self).__init__()\n",
    "        # Linear layer\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # Batch normalization layer\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        ## combinde\n",
    "        self.ffs=nn.Sequential(self.fc1,self.bn,nn.ReLU())\n",
    "\n",
    "        # Shortcut connection (identity mapping)\n",
    "        if input_size != hidden_size:\n",
    "            # If input and output dimensions are different, use a linear layer to match dimensions\n",
    "            self.shortcut = nn.Linear(input_size, hidden_size)\n",
    "        else:\n",
    "            # Identity mapping if dimensions match\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First linear transformation\n",
    "        #out = self.fc1(x)\n",
    "        \n",
    "        # Batch normalization and activation\n",
    "        #out = self.bn(out)\n",
    "        #out = F.relu(out)\n",
    "        \n",
    "        # Shortcut connection (adding the input to the transformed output)\n",
    "        shortcut = self.shortcut(x)\n",
    "        out =self.ffs(x)\n",
    "        out += shortcut\n",
    "        \n",
    "        # Pass through output layer\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Example usage\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 1\n",
    "model = ShortcutModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Example input tensor\n",
    "x = torch.randn(5, input_size)\n",
    "output = model(x)\n",
    "\n",
    "print(output)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShortcutModel(\n",
       "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
       "  (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=20, out_features=1, bias=True)\n",
       "  (ffs): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
       "    (1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (shortcut): Linear(in_features=10, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.optim.adam.Adam"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams[\"optimizer\"]=\"Adam\"\n",
    "getattr(torch.optim, hparams[\"optimizer\"].capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.loss.CrossEntropyLoss"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(torch.nn, \"CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.ones((1,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(10).reshape((2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = np.mean(x, axis=0)\n",
    "\n",
    "x_minus_mean = x - sample_mean[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.5, -2.5, -2.5, -2.5, -2.5],\n",
       "       [ 2.5,  2.5,  2.5,  2.5,  2.5]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_minus_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "num_conv_layer=4\n",
    "conv_layers=[nn.Conv2d(in_channels=2**(3+num_conv_layer-k), out_channels=2**(4+num_conv_layer-k), \\\n",
    "                               kernel_size=(k+1,k+1)) for k in range(num_conv_layer-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch\n",
    "model=resnet18(weights=ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn((1,3,240,240))\n",
    "model.to(\"mps\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=torch.randn((1,3,224,224)).to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=model.conv1 \n",
    "y1=c1(x0)\n",
    "b1=model.bn1 \n",
    "y2=b1(y1)\n",
    "relu1=model.relu \n",
    "y3=b1(y2)\n",
    "maxpool1=model.maxpool \n",
    "y4=maxpool1(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 64, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "print(x0.shape)\n",
    "print(y1.shape)\n",
    "print(y2.shape)\n",
    "print(y3.shape)\n",
    "print(y4.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=model.layer1\n",
    "x1=torch.randn((1,64,240,240)).to(\"mps\")\n",
    "l2=model.layer2\n",
    "x2=torch.randn((1,64,240,240)).to(\"mps\")\n",
    "\n",
    "l3=model.layer3\n",
    "x3=torch.randn((1,128,120,120)).to(\"mps\")\n",
    "l4=model.layer4\n",
    "x4=torch.randn((1,256,60,60)).to(\"mps\")\n",
    "avgpool=model.avgpool\n",
    "x5=torch.randn((1,512,30,30)).to(\"mps\")\n",
    "with torch.no_grad():\n",
    "    print(l1(x1).shape)\n",
    "    print(l2(x2).shape)\n",
    "    print(l3(x3).shape)\n",
    "    print(l4(x4).shape)\n",
    "    print(avgpool(x5).shape)\n",
    "    model.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(model.fc.in_features, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn((1,3,240,240))\n",
    "model.to(\"mps\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model.forward(x.to(\"mps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 2 2 2 2 2 3 3 3 3 3]\n",
      " [4 4 4 4 4 5 5 5 5 5 6 6 6 6 6]\n",
      " [7 7 7 7 7 8 8 8 8 8 9 9 9 9 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "  \n",
    "# declaring an array \n",
    "a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] \n",
    "  \n",
    "# use the repeat function to upsample the array \n",
    "print(np.repeat(a, 5, axis=1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(ResNet18, self).__init__()\n",
    "        \n",
    "        self.dropout_percentage = 0.5\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # BLOCK-1 (starting block) input=(224x224) output=(56x56)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(7,7), stride=(2,2), padding=(3,3))\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        \n",
    "        # BLOCK-2 (1) input=(56x56) output = (56x56)\n",
    "        self.conv2_1_1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm2_1_1 = nn.BatchNorm2d(64)\n",
    "        self.conv2_1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm2_1_2 = nn.BatchNorm2d(64)\n",
    "        self.dropout2_1 = nn.Dropout(p=self.dropout_percentage)\n",
    "        # BLOCK-2 (2)\n",
    "        self.conv2_2_1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm2_2_1 = nn.BatchNorm2d(64)\n",
    "        self.conv2_2_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm2_2_2 = nn.BatchNorm2d(64)\n",
    "        self.dropout2_2 = nn.Dropout(p=self.dropout_percentage)\n",
    "        \n",
    "        # BLOCK-3 (1) input=(56x56) output = (28x28)\n",
    "        self.conv3_1_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        self.batchnorm3_1_1 = nn.BatchNorm2d(128)\n",
    "        self.conv3_1_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm3_1_2 = nn.BatchNorm2d(128)\n",
    "        self.concat_adjust_3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(1,1), stride=(2,2), padding=(0,0))\n",
    "        self.dropout3_1 = nn.Dropout(p=self.dropout_percentage)\n",
    "        # BLOCK-3 (2)\n",
    "        self.conv3_2_1 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm3_2_1 = nn.BatchNorm2d(128)\n",
    "        self.conv3_2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm3_2_2 = nn.BatchNorm2d(128)\n",
    "        self.dropout3_2 = nn.Dropout(p=self.dropout_percentage)\n",
    "        \n",
    "        # BLOCK-4 (1) input=(28x28) output = (14x14)\n",
    "        self.conv4_1_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        self.batchnorm4_1_1 = nn.BatchNorm2d(256)\n",
    "        self.conv4_1_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm4_1_2 = nn.BatchNorm2d(256)\n",
    "        self.concat_adjust_4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(1,1), stride=(2,2), padding=(0,0))\n",
    "        self.dropout4_1 = nn.Dropout(p=self.dropout_percentage)\n",
    "        # BLOCK-4 (2)\n",
    "        self.conv4_2_1 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm4_2_1 = nn.BatchNorm2d(256)\n",
    "        self.conv4_2_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm4_2_2 = nn.BatchNorm2d(256)\n",
    "        self.dropout4_2 = nn.Dropout(p=self.dropout_percentage)\n",
    "        \n",
    "        # BLOCK-5 (1) input=(14x14) output = (7x7)\n",
    "        self.conv5_1_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        self.batchnorm5_1_1 = nn.BatchNorm2d(512)\n",
    "        self.conv5_1_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm5_1_2 = nn.BatchNorm2d(512)\n",
    "        self.concat_adjust_5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(1,1), stride=(2,2), padding=(0,0))\n",
    "        self.dropout5_1 = nn.Dropout(p=self.dropout_percentage)\n",
    "        # BLOCK-5 (2)\n",
    "        self.conv5_2_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm5_2_1 = nn.BatchNorm2d(512)\n",
    "        self.conv5_2_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.batchnorm5_2_2 = nn.BatchNorm2d(512)\n",
    "        self.dropout5_2 = nn.Dropout(p=self.dropout_percentage)\n",
    "        \n",
    "        # Final Block input=(7x7) \n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=(7,7), stride=(1,1))\n",
    "        self.fc = nn.Linear(in_features=1*1*512, out_features=1000)\n",
    "        self.out = nn.Linear(in_features=1000, out_features=n_classes)\n",
    "        # END\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # block 1 --> Starting block\n",
    "        x = self.relu(self.batchnorm1(self.conv1(x)))\n",
    "        op1 = self.maxpool1(x)\n",
    "        \n",
    "        \n",
    "        # block2 - 1\n",
    "        x = self.relu(self.batchnorm2_1_1(self.conv2_1_1(op1)))    # conv2_1 \n",
    "        x = self.batchnorm2_1_2(self.conv2_1_2(x))                 # conv2_1\n",
    "        x = self.dropout2_1(x)\n",
    "        # block2 - Adjust - No adjust in this layer as dimensions are already same\n",
    "        # block2 - Concatenate 1\n",
    "        op2_1 = self.relu(x + op1)\n",
    "        # block2 - 2\n",
    "        x = self.relu(self.batchnorm2_2_1(self.conv2_2_1(op2_1)))  # conv2_2 \n",
    "        x = self.batchnorm2_2_2(self.conv2_2_2(x))                 # conv2_2\n",
    "        x = self.dropout2_2(x)\n",
    "        # op - block2\n",
    "        op2 = self.relu(x + op2_1)\n",
    "    \n",
    "        \n",
    "        # block3 - 1[Convolution block]\n",
    "        x = self.relu(self.batchnorm3_1_1(self.conv3_1_1(op2)))    # conv3_1\n",
    "        x = self.batchnorm3_1_2(self.conv3_1_2(x))                 # conv3_1\n",
    "        x = self.dropout3_1(x)\n",
    "        # block3 - Adjust\n",
    "        op2 = self.concat_adjust_3(op2) # SKIP CONNECTION\n",
    "        # block3 - Concatenate 1\n",
    "        op3_1 = self.relu(x + op2)\n",
    "        # block3 - 2[Identity Block]\n",
    "        x = self.relu(self.batchnorm3_2_1(self.conv3_2_1(op3_1)))  # conv3_2\n",
    "        x = self.batchnorm3_2_2(self.conv3_2_2(x))                 # conv3_2 \n",
    "        x = self.dropout3_2(x)\n",
    "        # op - block3\n",
    "        op3 = self.relu(x + op3_1)\n",
    "        \n",
    "        \n",
    "        # block4 - 1[Convolition block]\n",
    "        x = self.relu(self.batchnorm4_1_1(self.conv4_1_1(op3)))    # conv4_1\n",
    "        x = self.batchnorm4_1_2(self.conv4_1_2(x))                 # conv4_1\n",
    "        x = self.dropout4_1(x)\n",
    "        # block4 - Adjust\n",
    "        op3 = self.concat_adjust_4(op3) # SKIP CONNECTION\n",
    "        # block4 - Concatenate 1\n",
    "        op4_1 = self.relu(x + op3)\n",
    "        # block4 - 2[Identity Block]\n",
    "        x = self.relu(self.batchnorm4_2_1(self.conv4_2_1(op4_1)))  # conv4_2\n",
    "        x = self.batchnorm4_2_2(self.conv4_2_2(x))                 # conv4_2\n",
    "        x = self.dropout4_2(x)\n",
    "        # op - block4\n",
    "        op4 = self.relu(x + op4_1)\n",
    "\n",
    "        \n",
    "        # block5 - 1[Convolution Block]\n",
    "        x = self.relu(self.batchnorm5_1_1(self.conv5_1_1(op4)))    # conv5_1\n",
    "        x = self.batchnorm5_1_2(self.conv5_1_2(x))                 # conv5_1\n",
    "        x = self.dropout5_1(x)\n",
    "        # block5 - Adjust\n",
    "        op4 = self.concat_adjust_5(op4) # SKIP CONNECTION\n",
    "        # block5 - Concatenate 1\n",
    "        op5_1 = self.relu(x + op4)\n",
    "        # block5 - 2[Identity Block]\n",
    "        x = self.relu(self.batchnorm5_2_1(self.conv5_2_1(op5_1)))  # conv5_2\n",
    "        x = self.batchnorm5_2_1(self.conv5_2_1(x))                 # conv5_2\n",
    "        x = self.dropout5_2(x)\n",
    "        # op - block5\n",
    "        op5 = self.relu(x + op5_1)\n",
    "\n",
    "\n",
    "        # FINAL BLOCK - classifier \n",
    "        x = self.avgpool(op5)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.relu(self.fc(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ResNet18(n_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11702530\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for parameter in model.parameters():\n",
    "    count+=len(parameter.reshape((-1)))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=224\n",
    "\n",
    "h=np.floor((h-1)/2)+1\n",
    "np.floor((h-1)/2)+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
